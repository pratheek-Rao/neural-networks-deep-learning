{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNM2REu8lluv+IUzle6mgHq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pratheek-Rao/neural-networks-deep-learning/blob/main/next_word_prediction_using_RNN_and_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8qnLeLG6Hbv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "5sMoVXBe6s-l"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"this is a sample text used to demonstrate predictive text with basic RNNs.In this example, we'll predict the next word as you type.\""
      ],
      "metadata": {
        "id": "0djznV8jBuH_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=tf.keras.layers.TextVectorization()\n",
        "tokenizer.adapt(text.split())"
      ],
      "metadata": {
        "id": "eQDS8ud7Cq48"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_sequences=tokenizer(text)\n",
        "text_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIG3H4nZC9As",
        "outputId": "1143bea0-f424-455f-f254-a6e75ebbaf73"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(23,), dtype=int64, numpy=\n",
              "array([ 2, 17, 22, 12,  3,  8, 10, 19, 14,  3,  6, 20, 13,  2, 18,  7, 15,\n",
              "       11, 16,  5, 21,  4,  9])>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=text_sequences[:-1]\n",
        "y=text_sequences[1:]"
      ],
      "metadata": {
        "id": "J_tP9gcFDE3d"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=len(tokenizer.get_vocabulary()),output_dim=64,input_length=1),\n",
        "    tf.keras.layers.SimpleRNN(128,return_sequences=True),\n",
        "    tf.keras.layers.Dense(len(tokenizer.get_vocabulary()),activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "9xnsHwNHD3ye"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam')"
      ],
      "metadata": {
        "id": "cLt6J_ugFYFb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x,y,epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4Db4A6cF20N",
        "outputId": "a184395d-dda7-47d0-bb12-3c2bc8ff402d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 2s 2s/step - loss: 3.1348\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.1208\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.1069\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.0930\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.0790\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0649\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.0508\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.0364\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.0219\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0072\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.9922\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.9769\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.9612\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.9452\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.9287\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.9118\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.8945\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.8766\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.8581\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8391\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.8194\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.7991\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.7781\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.7564\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.7340\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.7108\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.6868\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.6620\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.6363\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.6098\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.5824\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.5541\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5248\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.4945\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.4633\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.4311\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.3979\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.3637\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.3285\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2922\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2549\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2166\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1773\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.1370\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0957\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0534\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.0102\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.9660\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.9210\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.8752\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c74701269b0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_next_word(seed_text):\n",
        "  seed_sequence=tokenizer(seed_text)\n",
        "  predicted_probabilities=model.predict(seed_sequence)\n",
        "  predicted_index=np.argmax(predicted_probabilities)\n",
        "  predicted_word=tokenizer.get_vocabulary()[predicted_index]\n",
        "  return predicted_word"
      ],
      "metadata": {
        "id": "euX62VHOHkp_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text=\"used\"\n",
        "predicted_word=generate_next_word(input_text)\n",
        "print(f\"Input:'{input_text}',Predicted:'{predicted_word}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wea5Xsy6I97G",
        "outputId": "802868cb-7613-4384-86df-0b337dada752"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 379ms/step\n",
            "Input:'used',Predicted:'to'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G4BpA4LRJjQB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}